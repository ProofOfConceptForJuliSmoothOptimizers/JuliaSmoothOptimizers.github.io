<!doctype html> <html lang=en > <meta charset=UTF-8 > <meta name=viewport  content="width=device-width, initial-scale=1"> <link rel=stylesheet  href="/previews/PR1/libs/katex/katex.min.css"> <link rel=stylesheet  href="/previews/PR1/libs/highlight/github.min.css"> <link rel=stylesheet  href="/previews/PR1/css/franklin.css"> <link rel=stylesheet  href="/previews/PR1/css/poole_hyde.css"> <style> html {font-size: 17px;} .franklin-content {position: relative; padding-left: 8%; padding-right: 5%; line-height: 1.35em;} @media (min-width: 940px) { .franklin-content {width: 100%; margin-left: auto; margin-right: auto;} } @media (max-width: 768px) { .franklin-content {padding-left: 6%; padding-right: 6%;} } </style> <link rel=icon  href="/previews/PR1/assets/favicon.png"> <title>How to solve a small optimization problem with Ipopt + NLPModels</title> <link rel=stylesheet  href="/previews/PR1/css/custom.css"> <link rel=preconnect  href="https://fonts.gstatic.com"> <link href="https://fonts.googleapis.com/css2?family=Nunito&family=Montserrat&display=swap" rel=stylesheet > <script src="/previews/PR1/libs/highlight/highlight.pack.js"></script> <!--TODO: Add EVERYTHING-->> <script> hljs.getLanguage('julia').keywords.custom = 'obj grad hess AbstractNLPModel'; </script>" <div class=sidebar > <div class="container sidebar-sticky"> <div class=sidebar-about > <img src="/previews/PR1/assets/jso.png"> <h1><a href="/previews/PR1/">JSO</a></h1> <p class=lead >Julia Smooth Optimizers.</p> </div> <nav class=sidebar-nav > <a class="sidebar-nav-item " href="/previews/PR1/">Home</a> <a class="sidebar-nav-item " href="/previews/PR1/pages/tutorials/list/">Tutorials</a> <a class="sidebar-nav-item " href="/previews/PR1/pages/ecosystem/list/">Ecosystems</a> <a class="sidebar-nav-item " href="/previews/PR1/pages/how-to/list/">How-to guide</a> <a class="sidebar-nav-item " href="/previews/PR1/pages/reference/list/">Reference guides</a> </nav> <p>&copy; Abel Soares Siqueira.</p> </div> </div> <div class="content container"> <div class=franklin-content ><h1 id=title ><a href="#title" class=header-anchor >How to solve a small optimization problem with Ipopt + NLPModels</a></h1> <div class=author >by Abel S. Siqueira</div> <p>To solve an optimization problem with Ipopt, the first thing to do is define your problem. In this example, let&#39;s assume we want to solve the following problem:</p> \[\begin{aligned} \text{min}_x \quad & (x_1 - 1)^2 + 4 (x_2 - x_1)^2 \\ \text{s.to} \quad & x_1^2 + x_2^2 \leq 1 \\ & x_1 \leq 0.5 \\ & 0.25 \leq x_2 \leq 0.75 \end{aligned}\] <p>Since our problem is simple, ADNLPModels is a perfect choice. It defines an model that uses automatic differentiation. It is just a matter of passing your functions and arrays to the constructor <code>ADNLPModel</code>.</p> <pre><code class=language-julia >using ADNLPModels

nlp &#61; ADNLPModel&#40;
  x -&gt; &#40;x&#91;1&#93; - 1&#41;^2 &#43; 4 * &#40;x&#91;2&#93; - x&#91;1&#93;^2&#41;, # f&#40;x&#41;
  &#91;0.5; 0.5&#93;, # starting point, which can be your guess
  &#91;-Inf; 0.25&#93;, # lower bounds on variables
  &#91;0.5; 0.75&#93;,  # upper bounds on variables
  x -&gt; &#91;x&#91;1&#93;^2 &#43; x&#91;2&#93;^2&#93;, # constraints function - must be an array
  &#91;-Inf&#93;, # lower bounds on constraints
  &#91;1.0&#93;   # upper bounds on constraints
&#41;</code></pre><pre><code class=plaintext >ADNLPModel - Model with automatic differentiation backend ADNLPModels.ForwardDiffAD()
  Problem name: Generic
   All variables: ████████████████████ 2      All constraints: ████████████████████ 1     
            free: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0                 free: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     
           lower: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0                lower: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     
           upper: ██████████⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 1                upper: ████████████████████ 1     
         low/upp: ██████████⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 1              low/upp: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     
           fixed: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0                fixed: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     
          infeas: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0               infeas: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     
            nnzh: (  0.00% sparsity)   3               linear: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     
                                                    nonlinear: ████████████████████ 1     
                                                         nnzj: (  0.00% sparsity)   2     

  Counters:
             obj: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0                 grad: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0                 cons: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     
            jcon: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0                jgrad: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0                  jac: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     
           jprod: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0               jtprod: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0                 hess: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     
           hprod: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0                jhess: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0               jhprod: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     
</code></pre> <p>Now, just pass your problem to ipopt.</p> <pre><code class=language-julia >using NLPModelsIpopt

output &#61; ipopt&#40;nlp&#41;</code></pre><pre><code class=plaintext >
******************************************************************************
This program contains Ipopt, a library for large-scale nonlinear optimization.
 Ipopt is released as open source code under the Eclipse Public License (EPL).
         For more information visit https://github.com/coin-or/Ipopt
******************************************************************************

This is Ipopt version 3.13.4, running with linear solver mumps.
NOTE: Other linear solvers might be more efficient (see Ipopt documentation).

Number of nonzeros in equality constraint Jacobian...:        0
Number of nonzeros in inequality constraint Jacobian.:        2
Number of nonzeros in Lagrangian Hessian.............:        3

Total number of variables............................:        2
                     variables with only lower bounds:        0
                variables with lower and upper bounds:        1
                     variables with only upper bounds:        1
Total number of equality constraints.................:        0
Total number of inequality constraints...............:        1
        inequality constraints with only lower bounds:        0
   inequality constraints with lower and upper bounds:        0
        inequality constraints with only upper bounds:        1

iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls
   0  1.2997000e+00 0.00e+00 4.29e+00  -1.0 0.00e+00    -  0.00e+00 0.00e+00   0
   1  4.5361290e-01 0.00e+00 2.41e+00  -1.0 4.35e-01    -  4.59e-01 6.35e-01f  1
   2  5.5431421e-01 0.00e+00 5.91e-02  -1.0 1.22e-01    -  1.00e+00 1.00e+00f  1
   3  3.0224698e-01 0.00e+00 1.58e-02  -1.7 5.64e-02    -  1.00e+00 1.00e+00f  1
   4  2.5558473e-01 0.00e+00 2.94e-04  -2.5 7.49e-03    -  1.00e+00 1.00e+00h  1
   5  2.5030180e-01 0.00e+00 5.43e-06  -3.8 6.84e-04    -  1.00e+00 1.00e+00h  1
   6  2.5000360e-01 0.00e+00 1.67e-08  -5.7 3.83e-05    -  1.00e+00 1.00e+00h  1
   7  2.4999992e-01 0.00e+00 2.49e-12  -8.6 4.64e-07    -  1.00e+00 1.00e+00h  1

Number of Iterations....: 7

                                   (scaled)                 (unscaled)
Objective...............:   2.4999991501233096e-01    2.4999991501233096e-01
Dual infeasibility......:   2.4923148672798348e-12    2.4923148672798348e-12
Constraint violation....:   0.0000000000000000e+00    0.0000000000000000e+00
Complementarity.........:   2.5082196362733705e-09    2.5082196362733705e-09
Overall NLP error.......:   2.5082196362733705e-09    2.5082196362733705e-09


Number of objective function evaluations             = 8
Number of objective gradient evaluations             = 8
Number of equality constraint evaluations            = 0
Number of inequality constraint evaluations          = 8
Number of equality constraint Jacobian evaluations   = 0
Number of inequality constraint Jacobian evaluations = 8
Number of Lagrangian Hessian evaluations             = 7
Total CPU secs in IPOPT (w/o function evaluations)   =      2.160
Total CPU secs in NLP function evaluations           =      1.102

EXIT: Optimal Solution Found.
"Execution stats: first-order stationary"</code></pre> <p>To remove the output, use print_level</p> <pre><code class=language-julia >output &#61; ipopt&#40;nlp, print_level&#61;0&#41;</code></pre><pre><code class=plaintext >"Execution stats: first-order stationary"</code></pre>
<p>The <code>output</code> variable containt essential information about the solution. They can be access with <code>.</code>.</p>
<pre><code class=language-julia >print&#40;output&#41;</code></pre><pre><code class=plaintext >Generic Execution stats
  status: first-order stationary
  objective value: 0.24999991501233096
  primal feasibility: 0.0
  dual feasibility: 2.4923148672798348e-12
  solution: [0.5  0.25]
  multipliers: [3.6454575515314157e-9]
  multipliers_L: [0.0  4.000000006828642]
  multipliers_U: [5.000000053347668  5.0084053323090786e-9]
  iterations: 7
  elapsed time: 0.004
  solver specific:
    real_time: 0.004628896713256836
    internal_msg: :Solve_Succeeded
</code></pre>
<pre><code class=language-julia >x &#61; output.solution
println&#40;&quot;Solution: &#36;x&quot;&#41;</code></pre><pre><code class=plaintext >Solution: [0.5, 0.25]
</code></pre>
<p>That&#39;s it. If your model is more complex, you should look into NLPModelsJuMP.jl. On the other hand, if you need more control and want to input your model manually, look for the specific how-to.</p>

<div class=page-foot >
  <div class=copyright >
    &copy; Abel Soares Siqueira. Last modified: April 22, 2021. Website built with <a href="https://github.com/tlienart/Franklin.jl">Franklin.jl</a> and the <a href="https://julialang.org">Julia programming language</a>.
  </div>
</div>
</div>
    </div>  
    
        <script src="/previews/PR1/libs/katex/katex.min.js"></script>
<script src="/previews/PR1/libs/katex/auto-render.min.js"></script>
<script>renderMathInElement(document.body)</script>

    
    
        
<script>hljs.initHighlightingOnLoad();hljs.configure({tabReplace: '    '});</script>